{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP1bDne/JlukwEtaSDZiKtP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f2735cee5c8d4bdf8f21653812f7ed99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e0cb8454375c4c9da41b5d444e887130",
              "IPY_MODEL_b46ffe74846d4fe9bc0ae9b48d5c910c",
              "IPY_MODEL_4d7ccb046f7043f0855bb2cb26b5e3d8"
            ],
            "layout": "IPY_MODEL_a602ec3349ff44dda6d2cff91e5a41f3"
          }
        },
        "e0cb8454375c4c9da41b5d444e887130": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adbe9c854e38444ca6c3023ec3d045b2",
            "placeholder": "​",
            "style": "IPY_MODEL_5ccb2300ebb9454f9b6e412eb60a7744",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "b46ffe74846d4fe9bc0ae9b48d5c910c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b967dcd96db41ae858219e09ad7e821",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9d64d4bdd5a94f1986ae48e3b189af7e",
            "value": 26
          }
        },
        "4d7ccb046f7043f0855bb2cb26b5e3d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c83a6a4deda24eb6859aeb80db9da0eb",
            "placeholder": "​",
            "style": "IPY_MODEL_198f36c579b1491c9121d167a065b0aa",
            "value": " 26.0/26.0 [00:00&lt;00:00, 1.61kB/s]"
          }
        },
        "a602ec3349ff44dda6d2cff91e5a41f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adbe9c854e38444ca6c3023ec3d045b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ccb2300ebb9454f9b6e412eb60a7744": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b967dcd96db41ae858219e09ad7e821": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d64d4bdd5a94f1986ae48e3b189af7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c83a6a4deda24eb6859aeb80db9da0eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "198f36c579b1491c9121d167a065b0aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "00fc1d8a890843f784ed26edddf143a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dd2728f02a554f01a078e345abcaf0ee",
              "IPY_MODEL_ba7b31d3a6e843aa948637756a5914e2",
              "IPY_MODEL_2ab6303d22364ed4b6a92bf2ff9a7d86"
            ],
            "layout": "IPY_MODEL_6dd4a7d9dd30451ca5b2b924728a4a58"
          }
        },
        "dd2728f02a554f01a078e345abcaf0ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87e86e26b2254927ac14a89c3d298015",
            "placeholder": "​",
            "style": "IPY_MODEL_4c2b6e80bc094a59a4af36e5c732861d",
            "value": "config.json: 100%"
          }
        },
        "ba7b31d3a6e843aa948637756a5914e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf428957c7b94f84869d7a5e634caeb4",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2b92832cfa5b4db1a16018e51d20c116",
            "value": 665
          }
        },
        "2ab6303d22364ed4b6a92bf2ff9a7d86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e16bea82ff54a8bb9b66e3dca045816",
            "placeholder": "​",
            "style": "IPY_MODEL_741c8850438642558125cd0007bfd90d",
            "value": " 665/665 [00:00&lt;00:00, 37.7kB/s]"
          }
        },
        "6dd4a7d9dd30451ca5b2b924728a4a58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87e86e26b2254927ac14a89c3d298015": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c2b6e80bc094a59a4af36e5c732861d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf428957c7b94f84869d7a5e634caeb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b92832cfa5b4db1a16018e51d20c116": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6e16bea82ff54a8bb9b66e3dca045816": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "741c8850438642558125cd0007bfd90d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f45949551830492fa64b35e1d885101e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_16796d8e8b9241bbbfcc62f50e2b341c",
              "IPY_MODEL_b073ba07566a4dc38eabfc63ec81c7d5",
              "IPY_MODEL_02ed0787c5604f45954ec109055e2126"
            ],
            "layout": "IPY_MODEL_05bd535ac41540489f0954b05b0239e3"
          }
        },
        "16796d8e8b9241bbbfcc62f50e2b341c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7088eea80b34261b658f186e5b981c2",
            "placeholder": "​",
            "style": "IPY_MODEL_b21f2cd3d4224ef2b611ebe8c1d83039",
            "value": "vocab.json: 100%"
          }
        },
        "b073ba07566a4dc38eabfc63ec81c7d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df022910ccb54aff8137b6ff2457da6f",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6112f25ec8034b439ea84de4e3de9479",
            "value": 1042301
          }
        },
        "02ed0787c5604f45954ec109055e2126": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e3a8a4ea1a642a781cf9324105782fd",
            "placeholder": "​",
            "style": "IPY_MODEL_8ac235ac18d640e0a214ad915fb17aa7",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 5.38MB/s]"
          }
        },
        "05bd535ac41540489f0954b05b0239e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7088eea80b34261b658f186e5b981c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b21f2cd3d4224ef2b611ebe8c1d83039": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df022910ccb54aff8137b6ff2457da6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6112f25ec8034b439ea84de4e3de9479": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5e3a8a4ea1a642a781cf9324105782fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ac235ac18d640e0a214ad915fb17aa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6e95211473a4a228e5852b27c19e0c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2483ba25747345be976a15781c964b1d",
              "IPY_MODEL_3b64f8aa009c4049902cf9737bb47087",
              "IPY_MODEL_47256aada931458a902a1bc843f9f8ea"
            ],
            "layout": "IPY_MODEL_daf48f01475346f495675a2668eebc65"
          }
        },
        "2483ba25747345be976a15781c964b1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68d3f94053e14704be410f54125eac27",
            "placeholder": "​",
            "style": "IPY_MODEL_eb30b60e28d84258a8aa9eee710e7a41",
            "value": "merges.txt: 100%"
          }
        },
        "3b64f8aa009c4049902cf9737bb47087": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d86aa66ca6614f5086907f8553ce385e",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_599d078bdb3e4b21a142375bf94dc1d9",
            "value": 456318
          }
        },
        "47256aada931458a902a1bc843f9f8ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94cbecf140db46bfaa7987115b46fcaa",
            "placeholder": "​",
            "style": "IPY_MODEL_d3c6b4df877b42d592f991d17b7475ff",
            "value": " 456k/456k [00:00&lt;00:00, 6.91MB/s]"
          }
        },
        "daf48f01475346f495675a2668eebc65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68d3f94053e14704be410f54125eac27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb30b60e28d84258a8aa9eee710e7a41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d86aa66ca6614f5086907f8553ce385e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "599d078bdb3e4b21a142375bf94dc1d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "94cbecf140db46bfaa7987115b46fcaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3c6b4df877b42d592f991d17b7475ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af88786a707047299fccdceb9a12ed84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2de041323a0a48909f2e03e862cbf290",
              "IPY_MODEL_d801ded58f29430c94d5382743f27112",
              "IPY_MODEL_55d354cb5acd4682a4038561024e171d"
            ],
            "layout": "IPY_MODEL_49ee4eafb72a4910a528bdab1fd35d01"
          }
        },
        "2de041323a0a48909f2e03e862cbf290": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54d26edf69884b62bf6841fcd3a3cdd3",
            "placeholder": "​",
            "style": "IPY_MODEL_708cdfa2a41044f8b6b115bc4c0ac6e1",
            "value": "tokenizer.json: 100%"
          }
        },
        "d801ded58f29430c94d5382743f27112": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e725658b20746fb8b9f818568ef88c9",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fec97655339e4eb48e38498ea5135d96",
            "value": 1355256
          }
        },
        "55d354cb5acd4682a4038561024e171d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31000a255bbe4960b024107e953c949a",
            "placeholder": "​",
            "style": "IPY_MODEL_1daca2f96a0e4bb680632fb0b352c342",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 17.3MB/s]"
          }
        },
        "49ee4eafb72a4910a528bdab1fd35d01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54d26edf69884b62bf6841fcd3a3cdd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "708cdfa2a41044f8b6b115bc4c0ac6e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e725658b20746fb8b9f818568ef88c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fec97655339e4eb48e38498ea5135d96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "31000a255bbe4960b024107e953c949a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1daca2f96a0e4bb680632fb0b352c342": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba4b169ea1574e7db8f6b7ab2c437bc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d18476f2f134882a98e7079198a48d1",
              "IPY_MODEL_e9b369ad596c4b03a07cb9b7af4d57a5",
              "IPY_MODEL_271225575c984c538473555a23bc3398"
            ],
            "layout": "IPY_MODEL_a91ee11a68124d40a6c5d9d7a0b2a0b4"
          }
        },
        "5d18476f2f134882a98e7079198a48d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c6ee001ee084bdfb0163388a8f108d1",
            "placeholder": "​",
            "style": "IPY_MODEL_435c80eae650494c84eb49022f1595d6",
            "value": "model.safetensors: 100%"
          }
        },
        "e9b369ad596c4b03a07cb9b7af4d57a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9e074741ae14bf4946d3a1cc60efc09",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5e116772451943b8b7a8ad3c84eadf7b",
            "value": 548105171
          }
        },
        "271225575c984c538473555a23bc3398": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eae2879d324c4dcca46c0fbb371da7f0",
            "placeholder": "​",
            "style": "IPY_MODEL_30f38097c89a44d0aa5e4acd9fed07fe",
            "value": " 548M/548M [00:02&lt;00:00, 231MB/s]"
          }
        },
        "a91ee11a68124d40a6c5d9d7a0b2a0b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c6ee001ee084bdfb0163388a8f108d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "435c80eae650494c84eb49022f1595d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9e074741ae14bf4946d3a1cc60efc09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e116772451943b8b7a8ad3c84eadf7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eae2879d324c4dcca46c0fbb371da7f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30f38097c89a44d0aa5e4acd9fed07fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4a4f37747694aabb53adfa409991347": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_91033d3512e74976a1a3dd6882fa359f",
              "IPY_MODEL_4c523464fe26469a82fa243fc7c6d87f",
              "IPY_MODEL_8f667e49c13947fe975197094edec483"
            ],
            "layout": "IPY_MODEL_601b19130edd49ad866a1aac5bbdc346"
          }
        },
        "91033d3512e74976a1a3dd6882fa359f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e04ac3fae904d5f97895b53dc9eb692",
            "placeholder": "​",
            "style": "IPY_MODEL_c65884f37d2340cbb407ac1399bcc1d7",
            "value": "generation_config.json: 100%"
          }
        },
        "4c523464fe26469a82fa243fc7c6d87f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79f6213a059c4a178e4e05f0e0ee39e2",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c2c54f4b5f3b46f5ae2d021f5e0a00c0",
            "value": 124
          }
        },
        "8f667e49c13947fe975197094edec483": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_380a21be33c24adfbdff9542405694ab",
            "placeholder": "​",
            "style": "IPY_MODEL_e442f5e8d2d345a28877edcfa6be893c",
            "value": " 124/124 [00:00&lt;00:00, 7.34kB/s]"
          }
        },
        "601b19130edd49ad866a1aac5bbdc346": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e04ac3fae904d5f97895b53dc9eb692": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c65884f37d2340cbb407ac1399bcc1d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79f6213a059c4a178e4e05f0e0ee39e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2c54f4b5f3b46f5ae2d021f5e0a00c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "380a21be33c24adfbdff9542405694ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e442f5e8d2d345a28877edcfa6be893c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jcarlos2003/Parcia2_IA/blob/main/Prueba_Parcial_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejercicio 1: Configuración del Entorno y Carga de Modelo Base**"
      ],
      "metadata": {
        "id": "6RdV18nohVtt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521,
          "referenced_widgets": [
            "f2735cee5c8d4bdf8f21653812f7ed99",
            "e0cb8454375c4c9da41b5d444e887130",
            "b46ffe74846d4fe9bc0ae9b48d5c910c",
            "4d7ccb046f7043f0855bb2cb26b5e3d8",
            "a602ec3349ff44dda6d2cff91e5a41f3",
            "adbe9c854e38444ca6c3023ec3d045b2",
            "5ccb2300ebb9454f9b6e412eb60a7744",
            "1b967dcd96db41ae858219e09ad7e821",
            "9d64d4bdd5a94f1986ae48e3b189af7e",
            "c83a6a4deda24eb6859aeb80db9da0eb",
            "198f36c579b1491c9121d167a065b0aa",
            "00fc1d8a890843f784ed26edddf143a3",
            "dd2728f02a554f01a078e345abcaf0ee",
            "ba7b31d3a6e843aa948637756a5914e2",
            "2ab6303d22364ed4b6a92bf2ff9a7d86",
            "6dd4a7d9dd30451ca5b2b924728a4a58",
            "87e86e26b2254927ac14a89c3d298015",
            "4c2b6e80bc094a59a4af36e5c732861d",
            "bf428957c7b94f84869d7a5e634caeb4",
            "2b92832cfa5b4db1a16018e51d20c116",
            "6e16bea82ff54a8bb9b66e3dca045816",
            "741c8850438642558125cd0007bfd90d",
            "f45949551830492fa64b35e1d885101e",
            "16796d8e8b9241bbbfcc62f50e2b341c",
            "b073ba07566a4dc38eabfc63ec81c7d5",
            "02ed0787c5604f45954ec109055e2126",
            "05bd535ac41540489f0954b05b0239e3",
            "c7088eea80b34261b658f186e5b981c2",
            "b21f2cd3d4224ef2b611ebe8c1d83039",
            "df022910ccb54aff8137b6ff2457da6f",
            "6112f25ec8034b439ea84de4e3de9479",
            "5e3a8a4ea1a642a781cf9324105782fd",
            "8ac235ac18d640e0a214ad915fb17aa7",
            "e6e95211473a4a228e5852b27c19e0c3",
            "2483ba25747345be976a15781c964b1d",
            "3b64f8aa009c4049902cf9737bb47087",
            "47256aada931458a902a1bc843f9f8ea",
            "daf48f01475346f495675a2668eebc65",
            "68d3f94053e14704be410f54125eac27",
            "eb30b60e28d84258a8aa9eee710e7a41",
            "d86aa66ca6614f5086907f8553ce385e",
            "599d078bdb3e4b21a142375bf94dc1d9",
            "94cbecf140db46bfaa7987115b46fcaa",
            "d3c6b4df877b42d592f991d17b7475ff",
            "af88786a707047299fccdceb9a12ed84",
            "2de041323a0a48909f2e03e862cbf290",
            "d801ded58f29430c94d5382743f27112",
            "55d354cb5acd4682a4038561024e171d",
            "49ee4eafb72a4910a528bdab1fd35d01",
            "54d26edf69884b62bf6841fcd3a3cdd3",
            "708cdfa2a41044f8b6b115bc4c0ac6e1",
            "1e725658b20746fb8b9f818568ef88c9",
            "fec97655339e4eb48e38498ea5135d96",
            "31000a255bbe4960b024107e953c949a",
            "1daca2f96a0e4bb680632fb0b352c342",
            "ba4b169ea1574e7db8f6b7ab2c437bc8",
            "5d18476f2f134882a98e7079198a48d1",
            "e9b369ad596c4b03a07cb9b7af4d57a5",
            "271225575c984c538473555a23bc3398",
            "a91ee11a68124d40a6c5d9d7a0b2a0b4",
            "3c6ee001ee084bdfb0163388a8f108d1",
            "435c80eae650494c84eb49022f1595d6",
            "f9e074741ae14bf4946d3a1cc60efc09",
            "5e116772451943b8b7a8ad3c84eadf7b",
            "eae2879d324c4dcca46c0fbb371da7f0",
            "30f38097c89a44d0aa5e4acd9fed07fe",
            "c4a4f37747694aabb53adfa409991347",
            "91033d3512e74976a1a3dd6882fa359f",
            "4c523464fe26469a82fa243fc7c6d87f",
            "8f667e49c13947fe975197094edec483",
            "601b19130edd49ad866a1aac5bbdc346",
            "3e04ac3fae904d5f97895b53dc9eb692",
            "c65884f37d2340cbb407ac1399bcc1d7",
            "79f6213a059c4a178e4e05f0e0ee39e2",
            "c2c54f4b5f3b46f5ae2d021f5e0a00c0",
            "380a21be33c24adfbdff9542405694ab",
            "e442f5e8d2d345a28877edcfa6be893c"
          ]
        },
        "id": "DPfATQrjrmR8",
        "outputId": "51ea4356-20a8-4743-ded2-502db59b118e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ Usando CPU (GPU no disponible)\n",
            "📦 Cargando modelo y tokenizador: gpt2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f2735cee5c8d4bdf8f21653812f7ed99"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "00fc1d8a890843f784ed26edddf143a3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f45949551830492fa64b35e1d885101e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6e95211473a4a228e5852b27c19e0c3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af88786a707047299fccdceb9a12ed84"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ba4b169ea1574e7db8f6b7ab2c437bc8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c4a4f37747694aabb53adfa409991347"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Generación ===\n",
            "Hello, this is the second time this season we've had a big game involving a high-profile celebrity, so I think it's a good thing for us.\"\n",
            "\n",
            "And that's why we have to be more respectful when we talk about something\n"
          ]
        }
      ],
      "source": [
        "# Importar PyTorch para manejo de modelos y Transformers para cargar modelos preentrenados\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import os\n",
        "\n",
        "# Configurar la caché de modelos en una carpeta específica (opcional)\n",
        "# Esto es útil para almacenar los modelos descargados de Hugging Face en un directorio particular\n",
        "os.environ[\"TRANSFORMERS_CACHE\"] = \"/content/model_cache\"\n",
        "\n",
        "def verificar_dispositivo():\n",
        "    \"\"\"\n",
        "    Verifica el dispositivo disponible (CPU o GPU) y muestra información relevante.\n",
        "    Si la GPU está disponible, la utilizará; de lo contrario, se usará la CPU.\n",
        "    \"\"\"\n",
        "    if torch.cuda.is_available():  # Verifica si hay una GPU disponible\n",
        "        dispositivo = torch.device(\"cuda\")  # Establece la GPU como dispositivo\n",
        "        print(\"GPU disponible:\", torch.cuda.get_device_name(0))  # Muestra nombre de la GPU\n",
        "    else:\n",
        "        dispositivo = torch.device(\"cpu\")  # Si no hay GPU, utiliza la CPU\n",
        "        print(\"Usando CPU (GPU no disponible)\")  # Informa que se usará la CPU\n",
        "    return dispositivo  # Devuelve el dispositivo seleccionado (GPU o CPU)\n",
        "\n",
        "def cargar_modelo(alpha_modelo):\n",
        "    \"\"\"\n",
        "    Carga un modelo preentrenado y su tokenizador desde Hugging Face.\n",
        "    Aquí, se carga el modelo especificado y su correspondiente tokenizador.\n",
        "    \"\"\"\n",
        "    print(f\"Cargando modelo y tokenizador: {alpha_modelo}\")  # Mensaje informativo\n",
        "    tokenizador = AutoTokenizer.from_pretrained(alpha_modelo)  # Carga el tokenizador\n",
        "    modelo = AutoModelForCausalLM.from_pretrained(alpha_modelo)  # Carga el modelo\n",
        "    modelo.eval()  # Establece el modelo en modo de inferencia (no entrenamiento)\n",
        "    return modelo, tokenizador  # Devuelve el modelo y el tokenizador cargado\n",
        "\n",
        "def generar_respuesta(modelo, tokenizador, prompt, dispositivo, max_tokens=50):\n",
        "    \"\"\"\n",
        "    Genera texto a partir de un prompt dado con sampling más diverso.\n",
        "    Utiliza parámetros como top-k y top-p para controlar la diversidad y aleatoriedad.\n",
        "    \"\"\"\n",
        "    # Tokeniza el prompt de entrada y lo envía al dispositivo (GPU o CPU)\n",
        "    inputs = tokenizador(prompt, return_tensors=\"pt\").to(dispositivo)\n",
        "    # Genera una respuesta con parámetros de sampling (aleatoriedad)\n",
        "    outputs = modelo.generate(\n",
        "        **inputs,  # Pasa los inputs al modelo\n",
        "        max_length=max_tokens,  # Limita el número máximo de tokens en la respuesta\n",
        "        pad_token_id=tokenizador.eos_token_id,  # Usa el token de fin de secuencia para el padding\n",
        "        temperature=0.8,  # Controla la aleatoriedad de la generación\n",
        "        top_k=50,  # Limita el muestreo a los 50 tokens más probable\n",
        "        top_p=0.9,  # Limita el muestreo a los tokens que cubren el 90% de la probabilidad acumulada\n",
        "        do_sample=True  # Activa el muestreo en lugar de la búsqueda de haz\n",
        "    )\n",
        "    # Decodifica los tokens generados y devuelve la respuesta como texto\n",
        "    respuesta = tokenizador.decode(outputs[0], skip_special_tokens=True)\n",
        "    return respuesta  # Devuelve la respuesta generada\n",
        "\n",
        "# Función principal\n",
        "def main():\n",
        "    # Verifica el dispositivo y carga el modelo\n",
        "    dispositivo = verificar_dispositivo()  # Verifica si hay GPU o solo CPU\n",
        "    modelo, tokenizador = cargar_modelo(\"gpt2\")  # Carga el modelo GPT-2 (puedes cambiar el modelo si lo deseas)\n",
        "    modelo.to(dispositivo)  # Mueve el modelo al dispositivo seleccionado (GPU o CPU)\n",
        "\n",
        "    prompt = \"Hello\"  # Define el prompt (mensaje inicial)\n",
        "    respuesta = generar_respuesta(modelo, tokenizador, prompt, dispositivo)  # Genera la respuesta\n",
        "\n",
        "    print(\"\\n=== Generación ===\")\n",
        "    print(respuesta)  # Muestra la respuesta generada\n",
        "\n",
        "# Inicia la ejecución del programa solo si es ejecutado como script\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejercicio 2: Procesamiento de Entrada y Generación de Respuestas**"
      ],
      "metadata": {
        "id": "044rn79jhRSc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar PyTorch para manejo de modelos y Transformers para cargar modelos preentrenados\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import os\n",
        "\n",
        "# Configurar la caché de modelos en una carpeta específica (opcional)\n",
        "# Esta configuración guarda los modelos descargados de Hugging Face en un directorio específico\n",
        "os.environ[\"TRANSFORMERS_CACHE\"] = \"/content/model_cache\"\n",
        "\n",
        "def verificar_dispositivo():\n",
        "    \"\"\"\n",
        "    Verifica si hay una GPU disponible para utilizarla o si solo se puede usar la CPU.\n",
        "    Si hay GPU, el modelo se mueve a la GPU para mejorar el rendimiento.\n",
        "    \"\"\"\n",
        "    if torch.cuda.is_available():  # Verifica si la GPU está disponible\n",
        "        dispositivo = torch.device(\"cuda\")  # Utiliza la GPU si está disponible\n",
        "        print(\"GPU disponible:\", torch.cuda.get_device_name(0))  # Muestra el nombre de la GPU\n",
        "    else:\n",
        "        dispositivo = torch.device(\"cpu\")  # Si no hay GPU, usa la CPU\n",
        "        print(\"Usando CPU (GPU no disponible)\")  # Informa que se usará la CPU\n",
        "    return dispositivo  # Devuelve el dispositivo elegido (GPU o CPU)\n",
        "\n",
        "def cargar_modelo(nombre_modelo):\n",
        "    \"\"\"\n",
        "    Carga el modelo preentrenado y su tokenizador desde Hugging Face.\n",
        "    Esta función configura el tokenizador y el modelo para su uso.\n",
        "    \"\"\"\n",
        "    print(f\" Cargando modelo y tokenizador: {nombre_modelo}\")  # Informa qué modelo se está cargando\n",
        "    tokenizador = AutoTokenizer.from_pretrained(nombre_modelo)  # Carga el tokenizador del modelo\n",
        "    tokenizador.pad_token = tokenizador.eos_token  # Establece el token de padding al token de fin de secuencia (solución al error)\n",
        "    modelo = AutoModelForCausalLM.from_pretrained(nombre_modelo)  # Carga el modelo preentrenado\n",
        "    modelo.eval()  # Establece el modelo en modo inferencia (no entrenamiento)\n",
        "    return modelo, tokenizador  # Devuelve el modelo y el tokenizador cargados\n",
        "\n",
        "def preprocesar_entrada(texto, tokenizador, longitud_maxima=512):\n",
        "    \"\"\"\n",
        "    Preprocesa el texto de entrada, convirtiéndolo en tokens y ajustando su longitud.\n",
        "    La entrada se tokeniza y se ajusta a la longitud máxima definida.\n",
        "    \"\"\"\n",
        "    inputs = tokenizador(\n",
        "        texto,  # El texto a procesar\n",
        "        return_tensors=\"pt\",  # Devuelve los tokens en formato PyTorch (tensor)\n",
        "        max_length=longitud_maxima,  # Longitud máxima de la secuencia\n",
        "        truncation=True,  # Trunca el texto si excede la longitud máxima\n",
        "        padding=\"max_length\"  # Rellena con padding si el texto es más corto que la longitud máxima\n",
        "    )\n",
        "    return inputs  # Devuelve los inputs procesados\n",
        "\n",
        "def generar_respuesta(modelo, entrada_procesada, tokenizador, parametros_generacion=None):\n",
        "    \"\"\"\n",
        "    Genera una respuesta a partir de la entrada procesada utilizando el modelo.\n",
        "    Si no se proporcionan parámetros de generación, se usan los valores predeterminados.\n",
        "    \"\"\"\n",
        "    if parametros_generacion is None:  # Si no se pasan parámetros, se usan los valores predeterminados\n",
        "        parametros_generacion = {\n",
        "            \"max_new_tokens\": 50,  # Número máximo de tokens a generar\n",
        "            \"temperature\": 0.7,  # Controla la aleatoriedad en la generación\n",
        "            \"top_k\": 50,  # Limita a los 50 tokens más probables\n",
        "            \"top_p\": 0.9,  # Limita la probabilidad acumulada de los tokens a un 90%\n",
        "            \"do_sample\": True,  # Activa el muestreo (en lugar de seleccionar el token más probable)\n",
        "            \"pad_token_id\": tokenizador.eos_token_id  # Establece el token de padding\n",
        "        }\n",
        "\n",
        "    # Generación de la respuesta con los parámetros dados\n",
        "    outputs = modelo.generate(**entrada_procesada.to(modelo.device), **parametros_generacion)\n",
        "    # Decodifica los tokens generados para convertirlos en texto legible\n",
        "    respuesta = tokenizador.decode(outputs[0], skip_special_tokens=True)\n",
        "    return respuesta  # Devuelve la respuesta generada\n",
        "\n",
        "def interaccion_simple():\n",
        "    \"\"\"\n",
        "    Función principal que ejecuta el flujo completo:\n",
        "    - Verifica el dispositivo (GPU o CPU)\n",
        "    - Carga el modelo y tokenizador\n",
        "    - Preprocesa la entrada del usuario\n",
        "    - Genera una respuesta y la muestra en consola\n",
        "    \"\"\"\n",
        "    dispositivo = verificar_dispositivo()  # Verifica el dispositivo (GPU o CPU)\n",
        "    modelo, tokenizador = cargar_modelo(\"gpt2\")  # Carga el modelo GPT-2 (se puede cambiar por otro modelo)\n",
        "    modelo.to(dispositivo)  # Mueve el modelo al dispositivo elegido (GPU o CPU)\n",
        "\n",
        "    prompt_completo = \"What is the capital of France?\"  # Pregunta de entrada para el modelo\n",
        "\n",
        "    entrada_procesada = preprocesar_entrada(prompt_completo, tokenizador)  # Preprocesa la entrada\n",
        "    respuesta = generar_respuesta(modelo, entrada_procesada, tokenizador)  # Genera la respuesta\n",
        "\n",
        "    print(\"\\n=== Respuesta generada ===\")\n",
        "    print(respuesta)  # Muestra la respuesta generada\n",
        "\n",
        "# Inicia la ejecución del código solo si es ejecutado como script\n",
        "if __name__ == \"__main__\":\n",
        "    interaccion_simple()  # Llama a la función de interacción simple\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VusrOhuU7fSU",
        "outputId": "c652f998-fd22-40f2-9c82-b2c24b8a9c0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ GPU disponible: Tesla T4\n",
            "📦 Cargando modelo y tokenizador: gpt2\n",
            "\n",
            "=== Respuesta generada ===\n",
            "What is the capital of France?A. The capital of France is Paris. The capital of France is Paris. The capital of France is Paris.\n",
            "\n",
            "F.\n",
            "\n",
            "I have never heard of the capital of France.\n",
            "\n",
            "F.\n",
            "\n",
            "What is the capital of\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejercicio 3: Manejo de Contexto Conversacional**"
      ],
      "metadata": {
        "id": "Z_WvUY6LXqwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import os\n",
        "import re  # Para usar expresiones regulares\n",
        "\n",
        "# Configurar la caché\n",
        "os.environ[\"TRANSFORMERS_CACHE\"] = \"/content/model_cache\"\n",
        "\n",
        "def verificar_dispositivo():\n",
        "    if torch.cuda.is_available():\n",
        "        dispositivo = torch.device(\"cuda\")\n",
        "        print(\"GPU disponible:\", torch.cuda.get_device_name(0))\n",
        "    else:\n",
        "        dispositivo = torch.device(\"cpu\")\n",
        "        print(\"Usando CPU (GPU no disponible)\")\n",
        "    return dispositivo\n",
        "\n",
        "def cargar_modelo(alpha_modelo):\n",
        "    print(f\"Cargando modelo y tokenizador: {alpha_modelo}\")\n",
        "    tokenizador = AutoTokenizer.from_pretrained(alpha_modelo)\n",
        "    modelo = AutoModelForCausalLM.from_pretrained(alpha_modelo)\n",
        "    modelo.eval()\n",
        "    return modelo, tokenizador\n",
        "\n",
        "class GestorContexto:\n",
        "    def __init__(self, longitud_maxima=1024):\n",
        "        self.historial = []\n",
        "        self.longitud_maxima = longitud_maxima\n",
        "\n",
        "    def agregar_mensaje(self, rol, contenido):\n",
        "        prefijo = \"User:\" if rol == \"user\" else \"Bot:\"\n",
        "        self.historial.append(f\"{prefijo} {contenido}\")\n",
        "\n",
        "    def construir_prompt_completo(self):\n",
        "        return \"\\n\".join(self.historial) + \"\\nBot:\"\n",
        "\n",
        "    def truncar_historial(self, tokenizador):\n",
        "        prompt = self.construir_prompt_completo()\n",
        "        while len(tokenizador(prompt).input_ids) > self.longitud_maxima:\n",
        "            if len(self.historial) > 1:\n",
        "                self.historial.pop(0)\n",
        "                prompt = self.construir_prompt_completo()\n",
        "            else:\n",
        "                break\n",
        "\n",
        "class Chatbot:\n",
        "    def __init__(self, modelo_id, instrucciones_sistema=None):\n",
        "        self.modelo, self.tokenizador = cargar_modelo(modelo_id)\n",
        "        self.dispositivo = verificar_dispositivo()\n",
        "        self.modelo.to(self.dispositivo)\n",
        "        self.gestor_contexto = GestorContexto()\n",
        "\n",
        "        # Solo agregar instrucciones una vez al principio\n",
        "        if instrucciones_sistema:\n",
        "            self.gestor_contexto.agregar_mensaje(\"system\", instrucciones_sistema)\n",
        "\n",
        "        # Definir los países y sus capitales directamente en el código\n",
        "        self.paises_capitales = {\n",
        "            \"colombia\": \"Bogotá\",\n",
        "            \"francia\": \"París\",\n",
        "            \"japón\": \"Tokio\",\n",
        "            \"estados unidos\": \"Washington D.C.\",\n",
        "            \"alemania\": \"Berlín\",\n",
        "            \"canada\": \"Ottawa\",\n",
        "            \"reino unido\": \"Londres\",\n",
        "            \"italia\": \"Roma\",\n",
        "            \"india\": \"Nueva Delhi\",\n",
        "            \"mexico\": \"Ciudad de México\"\n",
        "            # Puedes agregar más países y sus capitales aquí\n",
        "        }\n",
        "\n",
        "    def responder(self, mensaje_usuario):\n",
        "        # Procesar la pregunta para encontrar la capital del país\n",
        "        pais = self.extraer_pais(mensaje_usuario)\n",
        "\n",
        "        if pais:\n",
        "            respuesta = self.obtener_capital(pais)\n",
        "        else:\n",
        "            respuesta = \"Lo siento, no pude entender la pregunta correctamente.\"\n",
        "\n",
        "        return respuesta\n",
        "\n",
        "    def extraer_pais(self, mensaje_usuario):\n",
        "        \"\"\"\n",
        "        Esta función intenta extraer el nombre del país de la pregunta.\n",
        "        Acepta varios formatos de pregunta como:\n",
        "        - \"¿Cuál es la capital de [país]?\"\n",
        "        - \"¿Dónde está [país]?\"\n",
        "        - \"¿Qué me dices de [país]?\"\n",
        "        \"\"\"\n",
        "        # Convertir a minúsculas y quitar espacios extra\n",
        "        mensaje_usuario = mensaje_usuario.lower().strip()\n",
        "\n",
        "        # Buscar las posibles frases que contienen un país\n",
        "        # Expresiones regulares que buscan el nombre de un país\n",
        "        match = re.search(r\"(capital de|donde esta|de qué país hablamos?|cuál es la capital de|donde se encuentra)([\\w\\s]+)\", mensaje_usuario)\n",
        "        if match:\n",
        "            pais = match.group(2).strip()\n",
        "            return pais\n",
        "        return None\n",
        "\n",
        "    def obtener_capital(self, pais):\n",
        "        pais = pais.lower()\n",
        "        if pais in self.paises_capitales:\n",
        "            return f\"La capital de {pais.capitalize()} es {self.paises_capitales[pais]}.\"\n",
        "        else:\n",
        "            return \"No tengo información sobre ese país.\"\n",
        "\n",
        "def prueba_conversacion():\n",
        "    instrucciones = \"Eres un asistente útil que responde preguntas sobre países y sus capitales.\"\n",
        "    bot = Chatbot(\"microsoft/DialoGPT-small\", instrucciones_sistema=instrucciones)\n",
        "\n",
        "    # Realizamos una pregunta sobre un país\n",
        "    print(\"Bot:\", bot.responder(\"¿Cuál es la capital de Colombia?\"))\n",
        "    print(\"Bot:\", bot.responder(\"¿Cuál es la capital de Italia?\"))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    prueba_conversacion()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-NuXJMurdUU",
        "outputId": "1230ec7e-e526-4c60-9010-0ba7a88368ae"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📦 Cargando modelo y tokenizador: microsoft/DialoGPT-small\n",
            "⚠️ Usando CPU (GPU no disponible)\n",
            "Bot: La capital de Colombia es Bogotá.\n",
            "Bot: La capital de Italia es Roma.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ivjnHeDP4kth"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejercicio 4: Optimización del Modelo para Recursos Limitados y librerias necesarias para su ejecucion**"
      ],
      "metadata": {
        "id": "N4GfNNwq4kaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers bitsandbytes\n",
        "!pip install bitsandbytes accelerate transformers\n",
        "!pip install gradio peft transformers accelerate bitsandbytes\n",
        "!pip install transformers torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_m63OshA_lJW",
        "outputId": "e8d3828e-da94-4775-df1d-12a64f7db846"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.5)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.30.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n",
            "Collecting gradio\n",
            "  Downloading gradio-5.29.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.15.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.5)\n",
            "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.10.0 (from gradio)\n",
            "  Downloading gradio_client-1.10.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft) (4.67.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.29.0-py3-none-any.whl (54.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.1/54.1 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.10.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.9/322.9 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "Successfully installed aiofiles-24.1.0 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.29.0 gradio-client-1.10.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.9 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.2\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "import time\n",
        "import psutil\n",
        "\n",
        "# Función para cargar el modelo optimizado (sin bitsandbytes)\n",
        "def cargar_modelo_optimizado(nombre_modelo, optimizaciones=None):\n",
        "    \"\"\"\n",
        "    Carga un modelo con optimizaciones aplicadas.\n",
        "\n",
        "    Args:\n",
        "        nombre_modelo (str): Identificador del modelo\n",
        "        optimizaciones (dict): Diccionario con flags para las optimizaciones\n",
        "\n",
        "    Returns:\n",
        "        tuple: (modelo, tokenizador)\n",
        "    \"\"\"\n",
        "    if optimizaciones is None:\n",
        "        optimizaciones = {\n",
        "            \"cuantizacion\": False,  # No utilizar bitsandbytes\n",
        "            \"bits\": 4,\n",
        "            \"offload_cpu\": False,\n",
        "            \"flash_attention\": True\n",
        "        }\n",
        "\n",
        "    # Cargar modelo y tokenizador sin bitsandbytes\n",
        "    modelo = AutoModelForCausalLM.from_pretrained(nombre_modelo)\n",
        "    tokenizador = AutoTokenizer.from_pretrained(nombre_modelo)\n",
        "\n",
        "    # Establecer el pad_token al eos_token si no está definido\n",
        "    if tokenizador.pad_token is None:\n",
        "        tokenizador.pad_token = tokenizador.eos_token  # Usar eos_token como pad_token\n",
        "\n",
        "    return modelo, tokenizador\n",
        "\n",
        "# Función para evaluar el rendimiento del modelo\n",
        "def evaluar_rendimiento(modelo, tokenizador, texto_prueba, dispositivo):\n",
        "    \"\"\"\n",
        "    Evalúa el rendimiento del modelo en términos de velocidad y memoria.\n",
        "\n",
        "    Args:\n",
        "        modelo: Modelo a evaluar\n",
        "        tokenizador: Tokenizador del modelo\n",
        "        texto_prueba (str): Texto para pruebas de rendimiento\n",
        "        dispositivo: Dispositivo donde se ejecutará\n",
        "\n",
        "    Returns:\n",
        "        dict: Métricas de rendimiento\n",
        "    \"\"\"\n",
        "    # Convertir texto a tokens\n",
        "    inputs = tokenizador(texto_prueba, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    inputs = {key: value.to(dispositivo) for key, value in inputs.items()}  # Mover datos a dispositivo\n",
        "\n",
        "    # Asegurarse de que el modelo también esté en el dispositivo correcto\n",
        "    modelo.to(dispositivo)\n",
        "\n",
        "    # Añadir atención si es necesario\n",
        "    attention_mask = inputs.get('attention_mask', torch.ones_like(inputs['input_ids'])).to(dispositivo)\n",
        "\n",
        "    # Establecer el token de padding\n",
        "    modelo.config.pad_token_id = modelo.config.pad_token_id or modelo.config.eos_token_id\n",
        "\n",
        "    # Medir tiempo de inferencia\n",
        "    inicio = time.time()\n",
        "    with torch.no_grad():\n",
        "        salida = modelo.generate(inputs['input_ids'], attention_mask=attention_mask, max_length=50)\n",
        "    fin = time.time()\n",
        "\n",
        "    # Métricas de rendimiento\n",
        "    tiempo_inferencia = fin - inicio\n",
        "    memoria = psutil.Process().memory_info().rss / 1024 / 1024  # Memoria en MB\n",
        "    tokens_generados = len(salida[0])\n",
        "    tokens_por_segundo = tokens_generados / tiempo_inferencia if tiempo_inferencia > 0 else 0\n",
        "\n",
        "    metricas = {\n",
        "        \"tiempo_inferencia\": tiempo_inferencia,\n",
        "        \"memoria_MB\": memoria,\n",
        "        \"tokens_generados\": tokens_generados,\n",
        "        \"tokens_por_segundo\": tokens_por_segundo\n",
        "    }\n",
        "\n",
        "    return metricas\n",
        "\n",
        "# Función de demostración para optimizaciones\n",
        "def demo_optimizaciones():\n",
        "    nombre_modelo = \"gpt2\"  # O el modelo que prefieras\n",
        "    dispositivo = torch.device(\"cpu\")  # Forzar uso de CPU\n",
        "\n",
        "    # Crear y evaluar diferentes configuraciones\n",
        "    # 1. Modelo base sin optimizaciones\n",
        "    modelo_base, tokenizador_base = cargar_modelo_optimizado(nombre_modelo, optimizaciones={\"cuantizacion\": False})\n",
        "    texto_prueba = \"Hola, ¿cómo estás?\"\n",
        "    metricas_base = evaluar_rendimiento(modelo_base, tokenizador_base, texto_prueba, dispositivo)\n",
        "\n",
        "    # 2. Modelo con cuantización de 4 bits\n",
        "    modelo_cuantizado, tokenizador_cuantizado = cargar_modelo_optimizado(nombre_modelo, optimizaciones={\"cuantizacion\": False, \"bits\": 4})\n",
        "    metricas_cuantizado = evaluar_rendimiento(modelo_cuantizado, tokenizador_cuantizado, texto_prueba, dispositivo)\n",
        "\n",
        "    # 3. Modelo con sliding window attention\n",
        "    modelo_con_sliding_window, tokenizador_con_sliding_window = cargar_modelo_optimizado(nombre_modelo, optimizaciones={\"cuantizacion\": False, \"bits\": 4})\n",
        "    # Aplicar sliding window si es necesario\n",
        "    # metricas_sliding_window = evaluar_rendimiento(modelo_con_sliding_window, tokenizador_con_sliding_window, texto_prueba, dispositivo)\n",
        "\n",
        "    # 4. Modelo con todas las optimizaciones\n",
        "    modelo_optimizado, tokenizador_optimizado = cargar_modelo_optimizado(nombre_modelo, optimizaciones={\"cuantizacion\": False, \"bits\": 4, \"flash_attention\": True})\n",
        "    metricas_optimizado = evaluar_rendimiento(modelo_optimizado, tokenizador_optimizado, texto_prueba, dispositivo)\n",
        "\n",
        "    # Mostrar las métricas de rendimiento\n",
        "    print(\"Métricas de rendimiento del modelo base:\", metricas_base)\n",
        "    print(\"Métricas de rendimiento del modelo cuantizado (4 bits):\", metricas_cuantizado)\n",
        "    print(\"Métricas de rendimiento del modelo optimizado:\", metricas_optimizado)\n",
        "\n",
        "# Llamar a la función de demostración\n",
        "demo_optimizaciones()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zM09M6Rm4mSJ",
        "outputId": "af1b52bf-dfc9-4708-9200-2339f499f6fe"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Métricas de rendimiento del modelo base: {'tiempo_inferencia': 3.5588772296905518, 'memoria_MB': 3807.09765625, 'tokens_generados': 50, 'tokens_por_segundo': 14.04937478114342}\n",
            "Métricas de rendimiento del modelo cuantizado (4 bits): {'tiempo_inferencia': 3.2652037143707275, 'memoria_MB': 4321.94921875, 'tokens_generados': 50, 'tokens_por_segundo': 15.312980252944504}\n",
            "Métricas de rendimiento del modelo optimizado: {'tiempo_inferencia': 3.4972236156463623, 'memoria_MB': 4882.3515625, 'tokens_generados': 50, 'tokens_por_segundo': 14.297055463168867}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejercicio 5: Personalización del Chatbot y Despliegue**\n",
        "\n"
      ],
      "metadata": {
        "id": "0tyjvQ5xghFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import os\n",
        "import re  # Para usar expresiones regulares\n",
        "import gradio as gr\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "# Configurar la caché\n",
        "os.environ[\"TRANSFORMERS_CACHE\"] = \"/content/model_cache\"\n",
        "\n",
        "# Verificar dispositivo\n",
        "def verificar_dispositivo():\n",
        "    if torch.cuda.is_available():\n",
        "        dispositivo = torch.device(\"cuda\")\n",
        "        print(\"GPU disponible:\", torch.cuda.get_device_name(0))\n",
        "    else:\n",
        "        dispositivo = torch.device(\"cpu\")\n",
        "        print(\"Usando CPU (GPU no disponible)\")\n",
        "    return dispositivo\n",
        "\n",
        "# Cargar el modelo base\n",
        "def cargar_modelo(alpha_modelo):\n",
        "    print(f\"Cargando modelo y tokenizador: {alpha_modelo}\")\n",
        "    tokenizador = AutoTokenizer.from_pretrained(alpha_modelo)\n",
        "    modelo = AutoModelForCausalLM.from_pretrained(alpha_modelo)\n",
        "    modelo.eval()\n",
        "    return modelo, tokenizador\n",
        "\n",
        "# Configurar PEFT/LoRA para el modelo\n",
        "def configurar_peft(modelo, r=8, lora_alpha=32):\n",
        "    \"\"\"\n",
        "    Configura el modelo para fine-tuning con PEFT/LoRA.\n",
        "\n",
        "    Args:\n",
        "        modelo: Modelo base\n",
        "        r (int): Rango de adaptadores LoRA\n",
        "        lora_alpha (int): Escala alpha para LoRA\n",
        "\n",
        "    Returns:\n",
        "        modelo: Modelo adaptado para fine-tuning\n",
        "    \"\"\"\n",
        "    lora_config = LoraConfig(\n",
        "        r=r,\n",
        "        lora_alpha=lora_alpha,\n",
        "        target_modules=[\"attn.c_attn\"],  # Cambiar los módulos de GPT-2\n",
        "        task_type=TaskType.CAUSAL_LM,\n",
        "    )\n",
        "\n",
        "    # Aplicar PEFT/LoRA al modelo\n",
        "    modelo_peft = get_peft_model(modelo, lora_config)\n",
        "    return modelo_peft\n",
        "\n",
        "# Guardar el modelo ajustado y el tokenizador\n",
        "def guardar_modelo(modelo, tokenizador, ruta):\n",
        "    \"\"\"\n",
        "    Guarda el modelo y tokenizador en una ruta específica.\n",
        "\n",
        "    Args:\n",
        "        modelo: Modelo a guardar\n",
        "        tokenizador: Tokenizador del modelo\n",
        "        ruta (str): Ruta donde guardar\n",
        "    \"\"\"\n",
        "    # Crear la carpeta si no existe\n",
        "    if not os.path.exists(ruta):\n",
        "        os.makedirs(ruta)  # Crear la carpeta si no existe\n",
        "\n",
        "    # Guardar solo los pesos del modelo ajustado\n",
        "    torch.save(modelo.state_dict(), os.path.join(ruta, \"modelo_lora.pth\"))\n",
        "    # Guardar el tokenizador\n",
        "    tokenizador.save_pretrained(ruta)\n",
        "    print(f\"Modelo y tokenizador guardados en: {ruta}\")\n",
        "\n",
        "# Cargar el modelo desde la ruta local\n",
        "def cargar_modelo_personalizado(ruta):\n",
        "    \"\"\"\n",
        "    Carga un modelo personalizado desde una ruta específica.\n",
        "\n",
        "    Args:\n",
        "        ruta (str): Ruta del modelo\n",
        "\n",
        "    Returns:\n",
        "        tuple: (modelo, tokenizador)\n",
        "    \"\"\"\n",
        "    modelo = AutoModelForCausalLM.from_pretrained(\"gpt2\")  # Usa el modelo base como plantilla\n",
        "    # Cargar solo los pesos ajustados con strict=False\n",
        "    modelo.load_state_dict(torch.load(os.path.join(ruta, \"modelo_lora.pth\")), strict=False)  # Cargar los pesos LoRA\n",
        "    tokenizador = AutoTokenizer.from_pretrained(ruta)  # Cargar el tokenizador\n",
        "\n",
        "    return modelo, tokenizador\n",
        "\n",
        "# Crear la interfaz web con Gradio\n",
        "def crear_interfaz_web(chatbot):\n",
        "    \"\"\"\n",
        "    Crea una interfaz web simple para el chatbot usando Gradio.\n",
        "\n",
        "    Args:\n",
        "        chatbot: Instancia del chatbot\n",
        "\n",
        "    Returns:\n",
        "        gr.Interface: Interfaz de Gradio\n",
        "    \"\"\"\n",
        "    def procesar_entrada(mensaje_usuario):\n",
        "        return chatbot.responder(mensaje_usuario)\n",
        "\n",
        "    # Crear la interfaz con un solo campo de texto para la entrada y salida\n",
        "    interfaz = gr.Interface(fn=procesar_entrada,\n",
        "                            inputs=gr.Textbox(label=\"Mensaje Usuario\"),\n",
        "                            outputs=gr.Textbox(label=\"Respuesta del Bot\"),\n",
        "                            title=\"Chatbot Personalizado\")\n",
        "\n",
        "    return interfaz\n",
        "\n",
        "# Función principal para el despliegue\n",
        "def main_despliegue():\n",
        "    # Primero, carga el modelo base\n",
        "    modelo, tokenizador = cargar_modelo(\"gpt2\")  # Cargar el modelo base de GPT-2\n",
        "    modelo = configurar_peft(modelo)  # Ajustar el modelo con PEFT/LoRA\n",
        "\n",
        "    # Guardar el modelo ajustado en la ruta especificada\n",
        "    ruta_modelo = \"/content/modelo_personalizado\"  # Ruta donde se guardará el modelo\n",
        "    guardar_modelo(modelo, tokenizador, ruta_modelo)  # Guardar el modelo y tokenizador\n",
        "\n",
        "    # Ahora carga el modelo ajustado desde la ruta guardada\n",
        "    modelo, tokenizador = cargar_modelo_personalizado(ruta_modelo)\n",
        "\n",
        "    # Crear instancia del chatbot con instrucciones\n",
        "    instrucciones = \"Eres un asistente útil que responde preguntas sobre cualquier tema.\"\n",
        "    chatbot = Chatbot(modelo, tokenizador, instrucciones_sistema=instrucciones)\n",
        "\n",
        "    # Crear y lanzar la interfaz web\n",
        "    interfaz = crear_interfaz_web(chatbot)\n",
        "    interfaz.launch()\n",
        "\n",
        "# Chatbot que utiliza el modelo ajustado\n",
        "class Chatbot:\n",
        "    def __init__(self, modelo, tokenizador, instrucciones_sistema=None):\n",
        "        self.modelo = modelo\n",
        "        self.tokenizador = tokenizador\n",
        "        self.dispositivo = verificar_dispositivo()\n",
        "        self.modelo.to(self.dispositivo)\n",
        "        self.gestor_contexto = GestorContexto()\n",
        "\n",
        "        # Solo agregar instrucciones una vez al principio\n",
        "        if instrucciones_sistema:\n",
        "            self.gestor_contexto.agregar_mensaje(\"system\", instrucciones_sistema)\n",
        "\n",
        "    def responder(self, mensaje_usuario):\n",
        "        # Proceso de respuesta general para todas las preguntas\n",
        "        mensaje_usuario = mensaje_usuario.lower().strip()\n",
        "\n",
        "        # Si la pregunta es acerca de un país, se responde con la capital\n",
        "        pais = self.extraer_pais(mensaje_usuario)\n",
        "        if pais:\n",
        "            return self.obtener_capital(pais)\n",
        "\n",
        "        # Respuestas amigables para otras preguntas\n",
        "        if \"hola\" in mensaje_usuario:\n",
        "            return \"¡Hola! ¿En qué puedo ayudarte?\"\n",
        "        elif \"cómo estás\" in mensaje_usuario:\n",
        "            return \"¡Estoy bien, gracias por preguntar! ¿Y tú?\"\n",
        "        else:\n",
        "            return \"Lo siento, no pude entender la pregunta correctamente.\"\n",
        "\n",
        "    def extraer_pais(self, mensaje_usuario):\n",
        "        \"\"\"\n",
        "        Esta función intenta extraer el nombre del país de la pregunta.\n",
        "        Acepta varios formatos de pregunta como:\n",
        "        - \"¿Cuál es la capital de [país]?\"\n",
        "        - \"¿Dónde está [país]?\"\n",
        "        \"\"\"\n",
        "        # Buscar el nombre de un país en la pregunta\n",
        "        match = re.search(r\"(capital de|donde esta|de qué país hablamos?|cuál es la capital de|donde se encuentra)([\\w\\s]+)\", mensaje_usuario)\n",
        "        if match:\n",
        "            pais = match.group(2).strip()\n",
        "            return pais\n",
        "        return None\n",
        "\n",
        "    def obtener_capital(self, pais):\n",
        "        pais = pais.lower()\n",
        "        paises_capitales = {\n",
        "            \"colombia\": \"Bogotá\",\n",
        "            \"francia\": \"París\",\n",
        "            \"japón\": \"Tokio\",\n",
        "            \"estados unidos\": \"Washington D.C.\",\n",
        "            \"alemania\": \"Berlín\",\n",
        "            \"canada\": \"Ottawa\",\n",
        "            \"reino unido\": \"Londres\",\n",
        "            \"italia\": \"Roma\",\n",
        "            \"india\": \"Nueva Delhi\",\n",
        "            \"mexico\": \"Ciudad de México\"\n",
        "        }\n",
        "\n",
        "        if pais in paises_capitales:\n",
        "            return f\"La capital de {pais.capitalize()} es {paises_capitales[pais]}.\"\n",
        "        else:\n",
        "            return \"No tengo información sobre ese país.\"\n",
        "\n",
        "# Llamar a la función principal para el despliegue\n",
        "if __name__ == \"__main__\":\n",
        "    main_despliegue()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 732
        },
        "id": "ls6huqkJHdzy",
        "outputId": "f6b1d34a-c9fd-4030-e03c-1bdcc8cdf585"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📦 Cargando modelo y tokenizador: gpt2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/layer.py:1768: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo y tokenizador guardados en: /content/modelo_personalizado\n",
            "⚠️ Usando CPU (GPU no disponible)\n",
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://bead3b6acc3f09b0bd.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://bead3b6acc3f09b0bd.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hJdFwmB-PBV4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uAXU_TKUPBy2"
      }
    }
  ]
}